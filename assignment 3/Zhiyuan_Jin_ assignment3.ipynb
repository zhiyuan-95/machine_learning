{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daea82f2",
   "metadata": {},
   "source": [
    "### Part A: PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ec5418b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d296380",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "mnist=tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0031fa3c",
   "metadata": {},
   "source": [
    "#### 1. Perform Exploratory Data Analysis (EDA) on X_train and discuss the data and what you observe prior to beginning modeling (visualize the images) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e65b5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[0],\n",
    "           cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aa49be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reshaped =[]\n",
    "for x in X_train:\n",
    "    X_train_reshaped.append(x.reshape(1,784)[0])\n",
    "X_train = np.array(X_train_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "253dc254",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_reshaped = []\n",
    "for x in X_test:\n",
    "    X_test_reshaped.append(x.reshape(1,784)[0])\n",
    "X_test = np.array(X_test_reshaped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989efd98",
   "metadata": {},
   "source": [
    "In this data set, each data is 28*28 2 dimention image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f96dce6",
   "metadata": {},
   "source": [
    "##### 2. Normalize the image data so the pixel values are between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96ae0cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b43d265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0410355a",
   "metadata": {},
   "source": [
    "##### 3. Use PCA to reduce the 784 dimensions of the data to 32 dimensions using X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da65baa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (60000, 784)\n",
      "X_reduced shape: (60000, 32)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=32)\n",
    "X_reduced = pca.fit_transform(X_train)\n",
    "\n",
    "print('X shape:', X_train.shape)\n",
    "print('X_reduced shape:', X_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80e08db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1011809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690f0e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eca4199e",
   "metadata": {},
   "source": [
    "##### 4. Transform X_train, discuss the original variance in X_train and how much variance is explained by the 32 components. Plot the variance explained as a function of the number of components used and explain why the shape of the plot is what it is (use what we know about PCA) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5229d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original varience:  52.72503549512755\n",
      "variance explained by 32 components:  39.20506393222206\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22b1f064a60>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_var = np.sum(np.var(X_train,axis=0))\n",
    "print(\"original varience: \",np.sum(np.var(X_train,axis=0)))\n",
    "print('variance explained by 32 components: ', np.sum(pca.explained_variance_))\n",
    "plt.plot(pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee89564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c6f0d45",
   "metadata": {},
   "source": [
    "It means the top ranked components explain the most part of the varience of this data set, the explained variance geting less and less with the rank of the componant geting lower and lower."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e2feaf",
   "metadata": {},
   "source": [
    "##### 5. Using the transform fit on X_train, transform X_test and discuss the original variance in X_test and how much variance is explained on X_test by the 32 components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1b86335",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_test = PCA(n_components=32)\n",
    "pca_test.fit(X_train)\n",
    "test_reduced = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92f6ae9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22b1f133cd0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.var(test_reduced,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d792846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original test varience:  52.84824867142073\n",
      "variance explained by 32 components:  39.65644482082396\n"
     ]
    }
   ],
   "source": [
    "print(\"original test varience: \",np.sum(np.var(X_test,axis=0)))\n",
    "print('variance explained by 32 components: ', np.sum(np.var(test_reduced,axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d61b717",
   "metadata": {},
   "source": [
    "##### 6. Compare results from #4 and #5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90491217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4815d240",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[np.sum(np.var(X_train,axis=0)),np.sum(pca.explained_variance_)],[np.sum(np.var(X_test,axis=0)),np.sum(np.var(test_reduced,axis=0))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104ae0cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ce5e3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = pd.DataFrame(a,columns=['train','test'], index = ['total_var','explained_var'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d7a5c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_var</th>\n",
       "      <td>52.725035</td>\n",
       "      <td>39.205064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>explained_var</th>\n",
       "      <td>52.848249</td>\n",
       "      <td>39.656445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   train       test\n",
       "total_var      52.725035  39.205064\n",
       "explained_var  52.848249  39.656445"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc53caea",
   "metadata": {},
   "source": [
    "### Part B: AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8099e997",
   "metadata": {},
   "source": [
    "##### 1. Start with data after step #2 from Section A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48e9a114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48728d6",
   "metadata": {},
   "source": [
    "##### 2. Build an autoencoder (either at least 1 hidden layer or using CNN) that will reduce the 784 dimensions of the data to 32 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d854fc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "# This is the size of our encoded representations\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# This is our input image\n",
    "input_img = keras.Input(shape=(784,))\n",
    "\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = layers.Dense(encoding_dim, activation='relu')(input_img)\n",
    "\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = layers.Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "# This model maps an input to its reconstruction\n",
    "autoencoder = keras.Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8a15a4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a503425a",
   "metadata": {},
   "source": [
    "##### 3. Train an autoencoder on X_train. Discuss the original variance in X_train and how much variance is explained by the 32 dimensions. Hint: Use “model.predict(X_train)” to get predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfc49b6",
   "metadata": {},
   "source": [
    "configuration: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23abb7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam',loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "482ffa60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "235/235 [==============================] - 3s 10ms/step - loss: 0.2807 - val_loss: 0.1929\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.1724 - val_loss: 0.1551\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.1452 - val_loss: 0.1343\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.1293 - val_loss: 0.1220\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.1195 - val_loss: 0.1145\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.1124 - val_loss: 0.1073\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.1063 - val_loss: 0.1027\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.1023 - val_loss: 0.0993\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0994 - val_loss: 0.0971\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 0.0976 - val_loss: 0.0955\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0964 - val_loss: 0.0946\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 3s 15ms/step - loss: 0.0955 - val_loss: 0.0940\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0950 - val_loss: 0.0934\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 0.0946 - val_loss: 0.0932\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0944 - val_loss: 0.0929\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0942 - val_loss: 0.0927\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0940 - val_loss: 0.0927\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0939 - val_loss: 0.0925\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0937 - val_loss: 0.0924\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0936 - val_loss: 0.0923\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0935 - val_loss: 0.0922\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0935 - val_loss: 0.0922\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0934 - val_loss: 0.0921\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0933 - val_loss: 0.0921\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 0.0933 - val_loss: 0.0921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22b20ac2590>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(X_train, X_train,\n",
    "                epochs=25,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36c12909",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = autoencoder.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49c1d7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_var_train = np.sum(np.var(prediction,axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "216550a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_var_train = np.sum(np.var(X_train,axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47513d90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "explained_train = explained_var_train/total_var_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8018d7d3",
   "metadata": {},
   "source": [
    "##### 4. Using the model trained on X_train, transform X_test and discuss the original variance in X_test and how much variance is explained on X_test by the 32 dimensions of the autoencoder. Hint: Use “model.predict(X_test)” to get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4317f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = autoencoder.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f48b6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_var_test = np.sum(np.var(prediction,axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4155e385",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_var_test = np.sum(np.var(X_test, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eaf66503",
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_test = explained_var_test/total_var_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ce55fc",
   "metadata": {},
   "source": [
    "##### 5. Compare results from #3 and #4 and why it is important to test out of sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ece8c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare  = pd.DataFrame(index = ['train', 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6cd54833",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare['% variation_explained'] = [explained_train, explained_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02e88470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>% variation_explained</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.863104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.869264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       % variation_explained\n",
       "train               0.863104\n",
       "test                0.869264"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40fcae4",
   "metadata": {},
   "source": [
    "because we can test if our model is overfitted by testing out of sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598df0a2",
   "metadata": {},
   "source": [
    "### Part C: Explain Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b336bcd9",
   "metadata": {},
   "source": [
    "autoencoder explains more variantion, because PCA only explain linear relation ship, autoencoder can also explain non_linear relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e63cca",
   "metadata": {},
   "source": [
    "PCA has 784 parameters;\n",
    "autoencoder has 784x32x2+32+784 = 50992 parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed92eb34",
   "metadata": {},
   "source": [
    "we use PCA when the data set only has linear relationship, otherwise we use Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce55155",
   "metadata": {},
   "source": [
    "### Part D: Extra Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7c651616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "41e8c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(dt):\n",
    "    return 1/(1+np.exp(-dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "eaaf154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(dt):\n",
    "    return max(0,dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d79637de",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu = np.vectorize(relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0df8a0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def none(df):\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c2791600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drelu(x):\n",
    "    return x>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b829551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "drelu= np.vectorize(drelu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "28213b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "bc53d6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder:\n",
    "    def __init__(self,data_dim, encoding_dim, a1, a2):\n",
    "        self._a1 = a1\n",
    "        self._a2 = a2\n",
    "        self._ones = np.array([[1] for x in range(60000)])\n",
    "        self._data_dim = data_dim\n",
    "        self._m = 0 # data size\n",
    "        self._encoding_dim = encoding_dim\n",
    "        self._b1 = np.array([0. for x in range(encoding_dim)])\n",
    "        self._b2 = np.array([0. for x in range(data_dim)])\n",
    "        self._w1 = np.transpose([[(random.random()-0.5) for x in range(self._data_dim)] for y in range(self._encoding_dim)])\n",
    "        self._w2 = np.transpose([[(random.random()-0.5) for x in range(self._encoding_dim)] for y in range(self._data_dim)])\n",
    "        self._observed = np.array([])       \n",
    "        self._z = np.array([])\n",
    "        self._L = 0\n",
    "        self._y = np.array([])\n",
    "        self._ya = np.array([])\n",
    "        self._z = np.array([])\n",
    "        self._za = np.array([])\n",
    "        self._dL_dza = np.array([])\n",
    "        self._dza_dz = np.array([])\n",
    "        self._dL_dz = np.array([])\n",
    "        self._db2 = np.array([])\n",
    "        self._dw2 = np.array([])\n",
    "        self._dz_dya = np.array([])\n",
    "        self._dL_dya = np.array([])\n",
    "        self._dya_dy = np.array([])\n",
    "        self._dL_dy = np.array([])\n",
    "        self._db1 = np.array([])\n",
    "        self._dy_dw1 = np.array([])\n",
    "        self._dw1 = np.array([])\n",
    "\n",
    "    def encoder(self):\n",
    "        self._y = np.dot(self._observed,self._w1)+self._ones*self._b1 \n",
    "        self._ya = self._a1(self._y)\n",
    "    def decoder(self):\n",
    "        self._z = np.dot(self._ya, self._w2)+self._ones*self._b2\n",
    "        print(\"-\", end='')\n",
    "        self._za = self._a2(self._z)\n",
    "    def forward(self):\n",
    "        self.encoder()\n",
    "        print('-', end='')\n",
    "        self.decoder()\n",
    "        print(\"-\", end='')\n",
    "    def loss(self):\n",
    "        self._L = round(np.sum((self._observed-self._za)**2, axis=0)/(self._m),4)\n",
    "\n",
    "###decoding part backpropagation###\n",
    "    def dL_dza(self):\n",
    "        self._dL_dza = 2*(self._za-self._observed)/self._m\n",
    "    def dza_dz(self):\n",
    "        if self._a2==none:\n",
    "            self._dza_dz = 1\n",
    "        if self._a2==sigmoid:\n",
    "            self._dza_dz = self._za*(1-self._za)\n",
    "    def dL_dz(self):\n",
    "        self._dL_dz = self._dL_dza*self._dza_dz\n",
    "    def db2(self):\n",
    "        self._db2 = (np.sum(self._dL_dz,axis = 0).T)\n",
    "    def dw2(self):\n",
    "        self._dw2 = ((self._dL_dz.T).dot(self._ya).T)\n",
    "        print(\"-\", end='')\n",
    "###encoding part backpropagation###\n",
    "    def dz_dya(self):\n",
    "        self._dz_dya = self._w2.T\n",
    "    def dL_dya(self):\n",
    "        self._dL_dya = self._dL_dz.dot(self._dz_dya)\n",
    "    def dya_dy(self):\n",
    "         self._dya_dy = drelu(self._y)\n",
    "    def dL_dy(self):\n",
    "        self._dL_dy = (self._dL_dya*self._dya_dy).T\n",
    "    def db1(self):\n",
    "        self._db1 = np.sum(self._dL_dy.T,axis=0)\n",
    "    def dy_dw1(self):\n",
    "        self._dy_dw1 = self._observed\n",
    "    def dw1(self):\n",
    "        self._dw1 = (np.dot(self._dL_dy,self._dy_dw1).T)\n",
    "        print(\"-\", end='')\n",
    "    def update(self, learning_rate):\n",
    "        self._b2 -=learning_rate*self._db2\n",
    "        self._w2 -=learning_rate*self._dw2\n",
    "        self._b1 -=learning_rate*self._db1\n",
    "        self._w1 -=learning_rate*self._dw1\n",
    "    def backprop(self):\n",
    "        self.dL_dza()\n",
    "        self.dza_dz()\n",
    "        self.dL_dz()\n",
    "        self.db2()\n",
    "        self.dw2()\n",
    "        self.dz_dya()\n",
    "        self.dL_dya()\n",
    "        self.dya_dy()\n",
    "        self.dL_dy()\n",
    "        self.db1()\n",
    "        self.dy_dw1()\n",
    "        self.dw1()\n",
    "    def fit(self, input_data,learning_rate, itr):\n",
    "        self._observed = input_data\n",
    "        self._m = len(input_data)\n",
    "        for x in range(itr):\n",
    "            print('iteration', x+1, end=' ')\n",
    "            start_time = time.time()\n",
    "            self.forward()\n",
    "            self.backprop()\n",
    "            self.loss()\n",
    "            print(' loss:', self._L, '  var_explained: ', np.sum(np.var(self._za, axis = 0)), end='')\n",
    "            print(\"   --- %s seconds ---\" % round((time.time() - start_time),1))\n",
    "            self.update(learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65410eb",
   "metadata": {},
   "source": [
    "            \n",
    "    x -> y = f(x) -> ya = a1(y) --> z = g(ya) -> za= a2(z) -> L = loss(za)\n",
    "    f(x) = x*w1+b1\n",
    "    g(y) = y*w2+b2\n",
    "    a1 = ReLU \n",
    "    a2 = sigmoid\n",
    "    loss = ((za-x)^2)/m, m is the len of data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "69e49d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1 ----- loss: 6468.1726   var_explained:  2870.1616389395786   --- 3.7 seconds ---\n",
      "iteration 2 ----- loss: 1701.0651   var_explained:  661.9211041039644   --- 3.4 seconds ---\n",
      "iteration 3 ----- loss: 175.3994   var_explained:  7.834385159456377e-23   --- 3.7 seconds ---\n",
      "iteration 4 ----- loss: 131.2366   var_explained:  4.88288292783927e-23   --- 3.3 seconds ---\n",
      "iteration 5 ----- loss: 102.9724   var_explained:  3.969614567077857e-23   --- 3.4 seconds ---\n",
      "iteration 6 ----- loss: 84.8834   var_explained:  2.821535839301731e-23   --- 3.4 seconds ---\n",
      "iteration 7 ----- loss: 73.3064   var_explained:  2.30292541324234e-23   --- 3.4 seconds ---\n",
      "iteration 8 ----- loss: 65.8971   var_explained:  2.3672513877758436e-23   --- 3.4 seconds ---\n",
      "iteration 9 ----- loss: 61.1552   var_explained:  2.2816736648003716e-23   --- 3.4 seconds ---\n",
      "iteration 10 ----- loss: 58.1203   var_explained:  1.9497312625021006e-23   --- 3.5 seconds ---\n",
      "iteration 11 ----- loss: 56.178   var_explained:  2.331092595493745e-23   --- 3.4 seconds ---\n",
      "iteration 12 ----- loss: 54.9349   var_explained:  2.1177265163631897e-23   --- 3.4 seconds ---\n",
      "iteration 13 ----- loss: 54.1394   var_explained:  2.1162636620171317e-23   --- 3.4 seconds ---\n",
      "iteration 14 ----- loss: 53.6302   var_explained:  2.2494061070785422e-23   --- 3.4 seconds ---\n",
      "iteration 15 ----- loss: 53.3043   var_explained:  2.483736376605421e-23   --- 3.4 seconds ---\n",
      "iteration 16 ----- loss: 53.0958   var_explained:  2.240805262158799e-23   --- 3.4 seconds ---\n",
      "iteration 17 ----- loss: 52.9623   var_explained:  2.4032019635494746e-23   --- 3.4 seconds ---\n",
      "iteration 18 ----- loss: 52.8769   var_explained:  2.503160266354647e-23   --- 3.4 seconds ---\n",
      "iteration 19 ----- loss: 52.8222   var_explained:  2.402475598953297e-23   --- 3.5 seconds ---\n",
      "iteration 20 ----- loss: 52.7872   var_explained:  2.3506774876689046e-23   --- 3.4 seconds ---\n",
      "iteration 21 ----- loss: 52.7648   var_explained:  2.2750894579193798e-23   --- 3.4 seconds ---\n",
      "iteration 22 ----- loss: 52.7505   var_explained:  2.379761218223708e-23   --- 3.6 seconds ---\n",
      "iteration 23 ----- loss: 52.7413   var_explained:  2.5466173163866798e-23   --- 3.5 seconds ---\n",
      "iteration 24 ----- loss: 52.7355   var_explained:  2.2979239585038263e-23   --- 3.5 seconds ---\n",
      "iteration 25 ----- loss: 52.7317   var_explained:  2.670094498553915e-23   --- 3.4 seconds ---\n",
      "iteration 26 ----- loss: 52.7293   var_explained:  2.3099991355672705e-23   --- 3.5 seconds ---\n",
      "iteration 27 ----- loss: 52.7278   var_explained:  2.4418280023806516e-23   --- 3.6 seconds ---\n",
      "iteration 28 ----- loss: 52.7268   var_explained:  2.5082144118509863e-23   --- 3.4 seconds ---\n",
      "iteration 29 ----- loss: 52.7262   var_explained:  2.3786577800445814e-23   --- 3.4 seconds ---\n",
      "iteration 30 ----- loss: 52.7258   var_explained:  2.3557932368203053e-23   --- 3.4 seconds ---\n"
     ]
    }
   ],
   "source": [
    "ae = autoencoder(784,32, relu, none)\n",
    "ae.fit(X_train,0.1, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "531e50ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1 ----- loss: 288.9332   var_explained:  53.47038402557708   --- 4.9 seconds ---\n",
      "iteration 2 ----- loss: 210.5613   var_explained:  36.68905362997789   --- 4.8 seconds ---\n",
      "iteration 3 ----- loss: 181.7556   var_explained:  7.365220817083177   --- 5.0 seconds ---\n",
      "iteration 4 ----- loss: 180.1712   var_explained:  10.77387096263887   --- 4.7 seconds ---\n",
      "iteration 5 ----- loss: 175.1008   var_explained:  7.715892658281819   --- 4.8 seconds ---\n",
      "iteration 6 ----- loss: 173.0745   var_explained:  10.939163006208716   --- 5.0 seconds ---\n",
      "iteration 7 ----- loss: 171.2124   var_explained:  10.570968873520801   --- 4.8 seconds ---\n",
      "iteration 8 ----- loss: 166.6687   var_explained:  10.585145368766781   --- 4.9 seconds ---\n",
      "iteration 9 ----- loss: 172.865   var_explained:  17.77798394686599   --- 4.7 seconds ---\n",
      "iteration 10 ----- loss: 181.1951   var_explained:  15.13251569706449   --- 4.8 seconds ---\n",
      "iteration 11 ----- loss: 165.982   var_explained:  10.638924323475376   --- 4.7 seconds ---\n",
      "iteration 12 ----- loss: 157.1012   var_explained:  6.837363954135849   --- 5.2 seconds ---\n",
      "iteration 13 ----- loss: 166.9963   var_explained:  8.637713936333984   --- 5.1 seconds ---\n",
      "iteration 14 ----- loss: 154.5766   var_explained:  5.4782185067510465   --- 4.8 seconds ---\n",
      "iteration 15 ----- loss: 149.9714   var_explained:  1.3720740120070185   --- 4.8 seconds ---\n",
      "iteration 16 ----- loss: 147.7941   var_explained:  1.9188855585868687   --- 5.1 seconds ---\n",
      "iteration 17 ----- loss: 146.3484   var_explained:  3.4149643963194234   --- 5.0 seconds ---\n",
      "iteration 18 ----- loss: 143.3488   var_explained:  1.4507507233918366   --- 4.7 seconds ---\n",
      "iteration 19 ----- loss: 141.1979   var_explained:  1.754997857412983   --- 5.1 seconds ---\n",
      "iteration 20 ----- loss: 141.0133   var_explained:  4.970999323126158   --- 5.2 seconds ---\n",
      "iteration 21 ----- loss: 137.2626   var_explained:  2.8930621101274383   --- 4.7 seconds ---\n",
      "iteration 22 ----- loss: 165.1857   var_explained:  6.150253475498444   --- 5.0 seconds ---\n",
      "iteration 23 ----- loss: 136.413   var_explained:  4.330018073835737   --- 5.4 seconds ---\n",
      "iteration 24 ----- loss: 131.9098   var_explained:  0.9334053788716143   --- 5.0 seconds ---\n",
      "iteration 25 ----- loss: 130.13   var_explained:  0.9819823028310837   --- 5.2 seconds ---\n",
      "iteration 26 ----- loss: 128.5534   var_explained:  1.2719959764294686   --- 4.9 seconds ---\n",
      "iteration 27 ----- loss: 126.8285   var_explained:  1.2304828906819787   --- 4.7 seconds ---\n",
      "iteration 28 ----- loss: 125.3497   var_explained:  1.5098555998720251   --- 5.0 seconds ---\n",
      "iteration 29 ----- loss: 123.6032   var_explained:  1.3831908577741987   --- 5.3 seconds ---\n",
      "iteration 30 ----- loss: 122.9413   var_explained:  3.390033660479369   --- 4.7 seconds ---\n",
      "iteration 31 ----- loss: 121.2308   var_explained:  2.9953567771084852   --- 4.8 seconds ---\n",
      "iteration 32 ----- loss: 119.1445   var_explained:  1.1095436355802932   --- 5.6 seconds ---\n",
      "iteration 33 ----- loss: 118.7532   var_explained:  2.7248407075713015   --- 5.8 seconds ---\n",
      "iteration 34 ----- loss: 116.4768   var_explained:  2.8215495073228953   --- 5.4 seconds ---\n",
      "iteration 35 ----- loss: 115.344   var_explained:  3.490333361202247   --- 5.2 seconds ---\n",
      "iteration 36 ----- loss: 114.0396   var_explained:  1.2036582864795395   --- 4.9 seconds ---\n",
      "iteration 37 ----- loss: 112.6845   var_explained:  1.0740834556102614   --- 4.8 seconds ---\n",
      "iteration 38 ----- loss: 111.5313   var_explained:  1.2069533176452891   --- 4.8 seconds ---\n",
      "iteration 39 ----- loss: 110.3565   var_explained:  1.2543697172871986   --- 5.3 seconds ---\n",
      "iteration 40 ----- loss: 109.2373   var_explained:  1.341360487694772   --- 5.0 seconds ---\n",
      "iteration 41 ----- loss: 108.1412   var_explained:  1.4282164804272406   --- 4.9 seconds ---\n",
      "iteration 42 ----- loss: 107.0639   var_explained:  1.5153398159468965   --- 5.0 seconds ---\n",
      "iteration 43 ----- loss: 106.038   var_explained:  1.7318208310727568   --- 4.8 seconds ---\n",
      "iteration 44 ----- loss: 104.3619   var_explained:  2.5444868749778418   --- 4.9 seconds ---\n",
      "iteration 45 ----- loss: 158.0961   var_explained:  4.013724633354006   --- 4.9 seconds ---\n",
      "iteration 46 ----- loss: 132.7245   var_explained:  10.569468341671826   --- 5.6 seconds ---\n",
      "iteration 47 ----- loss: 102.4096   var_explained:  0.9265238087688727   --- 4.9 seconds ---\n",
      "iteration 48 ----- loss: 101.1889   var_explained:  0.5656256042578431   --- 4.7 seconds ---\n",
      "iteration 49 ----- loss: 100.2853   var_explained:  0.5619013502432579   --- 4.9 seconds ---\n",
      "iteration 50 ----- loss: 99.4128   var_explained:  0.5669744040983458   --- 4.8 seconds ---\n"
     ]
    }
   ],
   "source": [
    "ae = autoencoder(784,32, relu, sigmoid)\n",
    "ae.fit(X_train, 0.1, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c064d668",
   "metadata": {},
   "source": [
    "#### problems still exist in my autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a0857a",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "    the loss(sum of squared error) is decreasing which is good, but the explained variance is also decreasing which is weired and I don't know why. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6920b86f",
   "metadata": {},
   "source": [
    "    if I don't use second activation function, the loss decreases steady to a optimal number. \n",
    "    when I add sigmoid activation fucntion to the final output, the decrease of the loss is unstable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98833fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f38055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad3e11c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85daf99f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e982500d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db449928",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
